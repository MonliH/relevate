{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "lines = list(open(\"sentences.txt\", \"r\").readlines())\n",
    "\n",
    "def generate_filler():\n",
    "    if random.random() < 0.2:\n",
    "        return \"like\"\n",
    "    else:\n",
    "        uh = \"u\"\n",
    "        use_h = bool(random.getrandbits(1))\n",
    "        original_h = use_h\n",
    "        while use_h and len(uh) < 5:\n",
    "            uh += \"h\"\n",
    "            use_h = bool(random.getrandbits(1))\n",
    "\n",
    "        while not original_h or (bool(random.getrandbits(1)) and len(uh) < 5):\n",
    "            uh += \"m\"\n",
    "            original_h = True\n",
    "        \n",
    "        return uh\n",
    "\n",
    "def generate_stammer(word):\n",
    "    index_to_repeat = random.randrange(1, min(3, len(word))) if len(word) > 1 else 1\n",
    "    times_to_repeat = random.randrange(1, 3)\n",
    "    return (word[:index_to_repeat] + \"-\")*times_to_repeat\n",
    "\n",
    "def augment(line):\n",
    "    words = line.lower().split(\" \")\n",
    "    filler_num = random.randrange(0, 5)\n",
    "    stammer_num = random.randrange(0, 6-filler_num)\n",
    "    repeat_num = random.randrange(0, 3)\n",
    "    labels = [0]*len(words)\n",
    "\n",
    "    for _ in range(filler_num):\n",
    "        idx = random.randrange(0, len(words))\n",
    "        words.insert(idx, generate_filler())\n",
    "        labels.insert(idx, 1)\n",
    "\n",
    "    for _ in range(stammer_num):\n",
    "        idx = random.randrange(0, len(words))\n",
    "        words.insert(idx, generate_stammer(words[idx]))\n",
    "        labels.insert(idx, 1)\n",
    "\n",
    "    for _ in range(repeat_num):\n",
    "        idx = random.randrange(0, len(words))\n",
    "        words.insert(idx, words[idx])\n",
    "        labels.insert(idx, 1)\n",
    "\n",
    "    return words, labels\n",
    "\n",
    "new_ds = {\"tokens\": [], \"labels\": []}\n",
    "for _ in range(3):\n",
    "    for line in lines:\n",
    "        if line:\n",
    "            w, l = augment(line.strip())\n",
    "            new_ds[\"tokens\"].append(w)\n",
    "            new_ds[\"labels\"].append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd93383fbdb44aba90ec86d7605cd443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/2172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "ds = datasets.Dataset.from_dict(new_ds)\n",
    "ds.save_to_disk(\"./stutter-ds-2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
